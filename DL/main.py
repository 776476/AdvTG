"""
DLé˜¶æ®µä¸»è®­ç»ƒè„šæœ¬ - é‡æ„åçš„ç®€åŒ–ç‰ˆæœ¬
ä½¿ç”¨é…ç½®æ–‡ä»¶ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å‚æ•°
"""
import os
import sys
import time
import pickle
from concurrent.futures import ProcessPoolExecutor, as_completed

# ç¦ç”¨wandb - å¿…é¡»åœ¨å¯¼å…¥transformersä¹‹å‰è®¾ç½®
os.environ["WANDB_DISABLED"] = "true"
os.environ["WANDB_MODE"] = "disabled"

# è®¾ç½®é•œåƒç½‘ç«™ - ä¼˜å…ˆæœ¬åœ°ï¼Œæ— åˆ™ä»é•œåƒä¸‹è½½
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HUGGINGFACE_HUB_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HF_HUB_ENDPOINT"] = "https://hf-mirror.com"
os.environ["TRANSFORMERS_OFFLINE"] = "0"  # å…è®¸åœ¨çº¿ä¸‹è½½

# å¯¼å…¥å…¨å±€å¤šGPUé…ç½®
sys.path.append('..')
from multi_gpu_config import AdvTGMultiGPUConfig

# å¯¼å…¥DLé…ç½®å’Œç»„ä»¶
from config import DLConfig
from models import CNNLSTMClassifier, TextCNNClassifier, DNNClassifier, DeepLog
from data_processing import load_data, prepare_dataset, load_tokenizer, SimpleTokenizer
from training import train_transformer_model, train_custom_model
from utils import DLSwanLabCallback

# å¯¼å…¥å¿…è¦çš„åº“
import torch
from transformers import TrainingArguments, EarlyStoppingCallback


class DLTrainer:
    """DLé˜¶æ®µè®­ç»ƒå™¨ç±»"""
    
    def __init__(self):
        self.config = None
        self.dl_gpu_config = None
        self.global_gpu_config = None
        self.use_swanlab = False
        self.swanlab_run = None
        self.all_model_configs = []
    
    def initialize(self):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        # åˆå§‹åŒ–å…¨å±€å¤šGPUé…ç½®
        self.global_gpu_config = AdvTGMultiGPUConfig()
        self.dl_gpu_config = self.global_gpu_config.get_stage_config("DL")
        
        # åˆ›å»ºDLé…ç½®
        self.config = DLConfig(self.dl_gpu_config)
        
        # è®¾ç½®ç¯å¢ƒ
        self.config.setup_environment()
        self.config.create_directories()
        self.config.print_config_summary()
        
        # è®¾ç½®GPUä¼˜åŒ–
        device = self.config.setup_gpu_optimization()
        return device
    
    def setup_swanlab(self):
        """è®¾ç½®SwanLabå®éªŒè·Ÿè¸ª"""
        try:
            import swanlab
            experiment_name = f"AdvTG-DL-vLLM-{time.strftime('%Y%m%d-%H%M%S')}"
            
            self.swanlab_run = swanlab.init(
                project=self.config.SWANLAB_PROJECT,
                name=experiment_name,
                description=self.config.SWANLAB_DESCRIPTION,
                config=self.config.get_swanlab_config()
            )
            
            print("âœ… SwanLab initialized successfully!")
            print(f"ğŸ“Š Project: {self.config.SWANLAB_PROJECT}")
            print(f"ğŸ“Š Experiment: {experiment_name}")
            self.use_swanlab = True
            
        except ImportError:
            print("âš ï¸  SwanLab not installed, continuing without experiment tracking")
            self.use_swanlab = False
        except Exception as e:
            print(f"âš ï¸  SwanLab initialization failed: {e}")
            self.use_swanlab = False
    
    def load_and_prepare_data(self):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print("ğŸ“ Loading data...")
        json_data = load_data(self.config.DATA_PATH)
        
        # æ ¹æ®é…ç½®é€‰æ‹©tokenizer
        if self.config.FORCE_SIMPLE_MODE:
            print("Force simple mode enabled - using SimpleTokenizer")
            tokenizer = SimpleTokenizer()
        else:
            print(f"Model endpoint: {os.environ.get('HF_ENDPOINT', 'https://huggingface.co')}")
            tokenizer = load_tokenizer(self.config.BERT_MODEL_NAME)
        
        print(f"Tokenizer type: {type(tokenizer)}")
        print(f"Is SimpleTokenizer: {isinstance(tokenizer, SimpleTokenizer)}")
        
        # å‡†å¤‡æ•°æ®é›†
        train_dataset, val_dataset, test_dataset = prepare_dataset(
            json_data, tokenizer, self.config.MAX_LENGTH
        )
        
        return tokenizer, train_dataset, val_dataset, test_dataset
    
    def train_bert_model(self, tokenizer, train_dataset, val_dataset):
        """è®­ç»ƒBERTæ¨¡å‹"""
        if isinstance(tokenizer, SimpleTokenizer):
            print("Skipping BERT training - using simple tokenizer mode")
            return
        
        print("\n====== Training BERT Model ======")
        
        try:
            # åˆ›å»ºè®­ç»ƒå‚æ•°
            transformer_training_args = TrainingArguments(**self.config.get_transformer_training_args())
            
            # åˆ›å»ºå›è°ƒå‡½æ•°
            bert_callback = DLSwanLabCallback(use_swanlab=self.use_swanlab, model_name="BERT")
            early_stopping_callback = EarlyStoppingCallback(
                early_stopping_patience=self.config.EARLY_STOPPING_PATIENCE,
                early_stopping_threshold=self.config.EARLY_STOPPING_THRESHOLD
            )
            
            print(f"ğŸ›‘ BERT Early stopping enabled: patience={self.config.EARLY_STOPPING_PATIENCE}, threshold={self.config.EARLY_STOPPING_THRESHOLD}")
            
            # è®­ç»ƒæ¨¡å‹
            bert_save_path, bert_config = train_transformer_model(
                self.config.BERT_MODEL_NAME,
                self.config.BERT_MODEL_NAME,
                train_dataset,
                val_dataset,
                transformer_training_args,
                swanlab_callback=bert_callback,
                early_stopping_callback=early_stopping_callback
            )
            
            self.all_model_configs.append(bert_config)
            print("âœ… BERT model training completed!")
            
            # è®°å½•ç»“æœåˆ°SwanLab
            self._log_bert_results(bert_config)
            
        except Exception as e:
            print(f"âŒ BERT training failed: {e}")
            print("Continuing with custom models only...")
    
    def train_custom_models(self, train_dataset, val_dataset):
        """è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹"""
        print("\n====== Training Custom Models ======")
        
        # è·å–æ¨¡å‹å®šä¹‰
        models = self.config.get_model_definitions()
        
        # åˆ›å»ºè®­ç»ƒå‚æ•°
        custom_training_args = TrainingArguments(**self.config.get_custom_training_args())
        
        for model_name, model in models.items():
            print(f"\nğŸ”„ Training model: {model_name}")
            try:
                # è®­ç»ƒæ¨¡å‹
                save_path, model_config = train_custom_model(
                    model,
                    model_name,
                    train_dataset,
                    val_dataset,
                    custom_training_args,
                    swanlab_run=self.swanlab_run
                )
                
                self.all_model_configs.append(model_config)
                print(f"âœ… Completed training model: {model_name}")
                
                # è®°å½•ç»“æœåˆ°SwanLab
                self._log_custom_model_results(model_name, model_config)
                
            except Exception as e:
                print(f"âŒ Failed to train {model_name}: {e}")
    
    def _log_bert_results(self, bert_config):
        """è®°å½•BERTç»“æœåˆ°SwanLab"""
        if not self.use_swanlab:
            return
        
        try:
            import swanlab
            swanlab.log({
                'BERT_final_accuracy': bert_config.get('eval_accuracy', 0),
                'BERT_final_precision': bert_config.get('eval_precision', 0),
                'BERT_final_recall': bert_config.get('eval_recall', 0),
                'BERT_final_f1': bert_config.get('eval_f1', 0),
                'BERT_final_loss': bert_config.get('eval_loss', 0),
                'transformer_model_completed': 1
            })
            print(f"ğŸ“Š BERT final results logged to SwanLab")
        except Exception as e:
            print(f"âš ï¸  SwanLab logging failed for BERT: {e}")
    
    def _log_custom_model_results(self, model_name, model_config):
        """è®°å½•è‡ªå®šä¹‰æ¨¡å‹ç»“æœåˆ°SwanLab"""
        if not self.use_swanlab:
            return
        
        try:
            import swanlab
            swanlab.log({
                f'{model_name}_final_accuracy': model_config.get('accuracy', 0),
                f'{model_name}_final_precision': model_config.get('precision', 0),
                f'{model_name}_final_recall': model_config.get('recall', 0),
                f'{model_name}_final_f1': model_config.get('f1', 0),
                'custom_model_completed': 1
            })
            print(f"ğŸ“Š {model_name} final results logged to SwanLab")
        except Exception as e:
            print(f"âš ï¸  SwanLab logging failed for {model_name}: {e}")
    
    def save_configurations(self):
        """ä¿å­˜æ¨¡å‹é…ç½®"""
        with open(self.config.CONFIG_SAVE_PATH, 'wb') as f:
            pickle.dump(self.all_model_configs, f)
        
        print(f"\nâœ… Saved text model configurations to: {self.config.CONFIG_SAVE_PATH}")
        print(f"ğŸ“Š Total text models configured: {len(self.all_model_configs)}")
    
    def create_image_configs(self):
        """åˆ›å»ºå›¾åƒæ¨¡å‹é…ç½®"""
        try:
            from create_image_configs import create_image_model_configs
            create_image_model_configs()
            print("âœ… Created image model configurations")
        except Exception as e:
            print(f"âš ï¸  Failed to create image model configs: {e}")
    
    def finalize_training(self):
        """å®Œæˆè®­ç»ƒå¹¶è®°å½•æœ€ç»ˆç»“æœ"""
        if not self.use_swanlab:
            return
        
        try:
            import swanlab
            
            # è®°å½•æ‰€æœ‰æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
            for i, config in enumerate(self.all_model_configs):
                model_name = config.get('model_name', f'model_{i}')
                for metric in ['accuracy', 'f1', 'precision', 'recall']:
                    if metric in config:
                        swanlab.log({f"{model_name}/{metric}": config[metric]})
            
            # è®°å½•è®­ç»ƒæ‘˜è¦
            swanlab.log({
                "total_models_trained": len(self.all_model_configs),
                "training_completed": 1,
                "multi_gpu_optimization_enabled": 1 if self.config.GPU_COUNT > 1 else 0,
                "final_gpu_count": self.config.GPU_COUNT,
                "final_batch_size": self.config.BATCH_SIZE,
                "final_workers": self.dl_gpu_config.get('dataloader_num_workers', 4),
                "final_effective_batch_size": self.dl_gpu_config.get('effective_batch_size', self.config.BATCH_SIZE)
            })
            
            swanlab.finish()
            print("ğŸ“Š All results logged to SwanLab successfully!")
            
        except Exception as e:
            print(f"âš ï¸  SwanLab final logging failed: {e}")
    
    def run_training(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        print("ğŸš€ Starting AdvTG-DL training pipeline...")
        
        # 1. åˆå§‹åŒ–
        device = self.initialize()
        
        # 2. è®¾ç½®å®éªŒè·Ÿè¸ª
        self.setup_swanlab()
        
        # 3. åŠ è½½å’Œå‡†å¤‡æ•°æ®
        tokenizer, train_dataset, val_dataset, test_dataset = self.load_and_prepare_data()
        
        # 4. è®­ç»ƒBERTæ¨¡å‹
        self.train_bert_model(tokenizer, train_dataset, val_dataset)
        
        # 5. è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹
        self.train_custom_models(train_dataset, val_dataset)
        
        # 6. ä¿å­˜é…ç½®
        self.save_configurations()
        
        # 7. åˆ›å»ºå›¾åƒæ¨¡å‹é…ç½®
        self.create_image_configs()
        
        # 8. å®Œæˆè®­ç»ƒ
        self.finalize_training()
        
        print("\nğŸ‰ All models training completed with multi-GPU optimization!")


def main():
    """ä¸»å‡½æ•°"""
    trainer = DLTrainer()
    trainer.run_training()


if __name__ == "__main__":
    main()
